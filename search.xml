<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[每周分享-20180824]]></title>
    <url>%2F2018%2F08%2F24%2Fweekly-20180824%2F</url>
    <content type="text"><![CDATA[1. IDEA插件Statistic Intellij IDEA 代码统计插件 Statistic 可以快速有效地查看项目代码行数、文件数量，大小等； 2. Maven命令mvn dependency:getMaven命令行下载以来Jar包命令，如 mvn dependency:get -Dverbose -Dincludes=org.hibernate:hibernate-validator。该命令可以在IDEA执行卡顿的情况下，或者需要下载的依赖包久久都没有反应。可以使用此种方法下载具体的包。其他命令如dependency:tree可以查看具体包的多个依赖，从而排除冲突的jar包。 3. wc(word count) 命令 Linux的wc(word count)命令可以有效统计文本文件的大小，行数等；参考：https://alvinalexander.com/unix/edu/examples/wc.shtml 4. awk文本处理工具 Linux的awk是一个处理文本的强大工具；可以对文本文件执行各种操作。 5. Http 客户端工具：OkHttp OkHttp是一个有效的Http客户端，支持多个请求公用一个主机的socket，连接池减少请求时延，透明的gzip压缩了下载的大小，响应缓存完全避免网络重复请求等特点。github上的star达到28k，具体参考http://square.github.io/okhttp/； 6. HanLP 中文自然语言处理库HanLP是一个面向生产环境的自然语言处理工具包，能有效地对中文进行各种处理，包括句法分析、多种词法分析、中文分词、词性标注，命名实体识别、关键词提取，新词发现，短语提取，自动摘要，拼音简繁等。还支持自定义模型训练等。目前在github上有8k多的star，该项目由大快搜索主导并完全开源。参考 https://github.com/hankcs/HanLP。]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用Elasticsearch对文章进行分词统计]]></title>
    <url>%2F2018%2F08%2F21%2Fes-mapping-analysis%2F</url>
    <content type="text"><![CDATA[需求：通过公司名称，查询公司的统一社会信用代码(企查查)；使用统一社会信用代码，调用风报(收费)接口，找到公司的裁判文书信息；返回信息格式如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; &quot;_id&quot; : &quot;0533f2d0-6fc4-4f79-a5b6-bc6d33a2c3f0&quot;, &quot;法院&quot; : &quot;旌德县人民法院&quot;, &quot;案号&quot; : &quot;（2015）旌民二初字第00098号&quot;, &quot;案由&quot; : &quot;承揽合同纠纷&quot;, &quot;段落&quot; : [ &#123; &quot;标签&quot; : &quot;头部&quot;, &quot;内容&quot; : &quot;安徽省旌德县人民法院&quot; &#125;, &#123; &quot;标签&quot; : &quot;庭审程序说明&quot;, &quot;内容&quot; : &quot;被告贝利公司经本院传票传唤无正当理由未到庭参加诉讼。&quot; &#125;, &#123; &quot;标签&quot; : &quot;庭审程序说明&quot;, &quot;内容&quot; : &quot;本案现已审理终结。&quot; &#125;, &#123; &quot;标签&quot; : &quot;庭审过程其他&quot;, &quot;内容&quot; : &quot;原告为证明其诉讼主张，向本院递交的证据，被告樊建儿的质证意见及本院的认证意见如下：&quot; &#125;, &#123; &quot;标签&quot; : &quot;庭审过程其他&quot;, &quot;内容&quot; : &quot;2、《粉刷分项工程承包协议书》1份，证明两原告与被告贝利公司项目部签订协议，由原告分包粉刷工程，并对工程概况、范围、质量及保修、承包方式造价及付款进行了约定，明确了双方的权利义务。&quot; &#125;, &#123; &quot;标签&quot; : &quot;附件&quot;, &quot;内容&quot; : &quot;第一百四十四条被告经传票传唤，无正当理由拒不到庭的，或者未法庭许可中途退庭的，可以缺席判决。&quot; &#125; ], &quot;当事人&quot; : [ &#123; &quot;其他角色&quot; : [], &quot;名字&quot; : &quot;建儿&quot;, &quot;判决结果&quot; : &quot;败诉&quot;, &quot;角色&quot; : [ &quot;被告&quot; ], &quot;类型&quot; : &quot;人名&quot; &#125; ], &quot;文书类型&quot; : &quot;判决书&quot;, &quot;versions&quot; : 1, &quot;发布时间&quot; : &quot;2016-03-24&quot;, &quot;判决时间&quot; : &quot;2016-01-04&quot;, &quot;统一社会信用代码&quot; : &quot;91330110143843494L&quot;, &quot;标题&quot; : &quot;AAA与贝利建设集团有限公司合同纠纷一审民事判决书&quot;&#125; 需要对“段落.内容”进行分析。 一、 公司对于的社会统一信用代码公司名称 统一社会信用代码中建二局第一建筑工程有限公司：91110000104341301L浙江贝利 ：91330110143843494L河北太行建筑安装工程有限公司：91130606700751737C 二、 给“段落.标签”字段建立映射，使用中文ik_analyzer分词12345678910111213141516171819curl -X PUT &quot;localhost:9200/abs_enterprise_info&quot; -d&apos;&#123; &quot;mappings&quot;: &#123; &quot;cpws&quot;:&#123; &quot;properties&quot;:&#123; &quot;段落&quot;: &#123; &quot;type&quot;: &quot;object&quot;, &quot;properties&quot;:&#123; &quot;内容&quot;: &#123; &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;type&quot;: &quot;text&quot;, &quot;fielddata&quot;:&quot;true&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125;&apos; 建立完映射，可以对其进行分析，测试如下：12345curl -X POST &quot;localhost:9200/abs_enterprise_info/_analysis?pretty&quot; -d&apos;&#123; &quot;field&quot;: &quot;段落.内容&quot;, &quot;tags&quot;: &quot;上诉人深圳市明之辉建设工程有限公司（以下简称“明之辉公司”）因与被上诉人杨光权承揽合同纠纷一案，明之辉公司不服贵州省余庆县人民法院（2017）黔0329民初1802号民事判决，向本院提起上诉，本院于2018年1月5日立案受理后，依法组成合议庭审理了本案，本案现已审理终结。&quot;&#125;&apos; 三、 通过“统一社会信用代码”，查询符合的记录数（如有100条数据），再对其进行词频统计12345678910111213141516171819curl -X POST &quot;localhost:9200/abs_enterprise_info/_search?pretty&quot; -o 91130606700751737C.txt -d&apos;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;统一社会信用代码&quot;: &quot;91130606700751737C&quot; &#125; &#125;, &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;messages&quot;: &#123; &quot;terms&quot;: &#123; &quot;size&quot;: 10, &quot;field&quot;: &quot;段落.内容&quot;, &quot;include&quot;:&quot;[\u4E00-\u9FA5]&#123;2,6&#125;&quot;, &quot;exclude&quot; : &quot;.*百.*|.*人.*|.*市.*|.*一.*|.*二.*|.*三.*|.*四.*|.*五.*|.*六.*|.*七.*|.*八.*|.*九.*|.*十.*&quot; &#125; &#125; &#125;&#125;&apos; include：包含2-6个中文单词的bucket key；过滤key少于两个汉子的数据的方法，参考：http://www.mamicode.com/info-detail-1669192.html； excude: 通过正则表达式过滤掉一部分数据，注：过滤太多程序无法解析，会出现错误； -o:将结果输入到文件91130606700751737C.txt中；输出结果的格式：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&#123; &quot;took&quot; : 174, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 31, &quot;max_score&quot; : 0.0, &quot;hits&quot; : [ ] &#125;, &quot;aggregations&quot; : &#123; &quot;messages&quot; : &#123; &quot;doc_count_error_upper_bound&quot; : 21, &quot;sum_other_doc_count&quot; : 4102, &quot;buckets&quot; : [ &#123; &quot;key&quot; : &quot;依照&quot;, &quot;doc_count&quot; : 28 &#125;, &#123; &quot;key&quot; : &quot;太行&quot;, &quot;doc_count&quot; : 27 &#125;, &#123; &quot;key&quot; : &quot;如下&quot;, &quot;doc_count&quot; : 27 &#125;, &#123; &quot;key&quot; : &quot;工程&quot;, &quot;doc_count&quot; : 27 &#125;, &#123; &quot;key&quot; : &quot;建筑安装&quot;, &quot;doc_count&quot; : 27 &#125;, &#123; &quot;key&quot; : &quot;有限公司&quot;, &quot;doc_count&quot; : 27 &#125;, &#123; &quot;key&quot; : &quot;本院&quot;, &quot;doc_count&quot; : 27 &#125;, &#123; &quot;key&quot; : &quot;民事诉讼法&quot;, &quot;doc_count&quot; : 27 &#125;, &#123; &quot;key&quot; : &quot;河北&quot;, &quot;doc_count&quot; : 27 &#125;, &#123; &quot;key&quot; : &quot;原告&quot;, &quot;doc_count&quot; : 25 &#125; ] &#125; &#125;&#125; 如果想对某一类数据进行分析，可以使用query.bool：123456789curl -X POST &quot;localhost:9200/abs_enterprise_info/_search?pretty&quot; -d&apos;&#123; &quot;query&quot;: &#123; &quot;bool&quot;:&#123; &quot;must&quot;:&#123;&quot;match&quot;:&#123;&quot;统一社会信用代码&quot;: &quot;91330110143843494L&quot;&#125;&#125;, &quot;must&quot;:&#123;&quot;match&quot;:&#123;&quot;案由&quot;: &quot;建设工程施工合同纠纷&quot;&#125;&#125; &#125; &#125;&#125;&apos; 四、 使用awk对输出到文件的内容进一步处理，执行:awk -F”:” ‘{if($1~/key/) print $2}’ 91130606700751737C.txt &gt; 91130606700751737C_tag.txt只保留中文关键字,并将结果放到新的文件中(如：91130606700751737C_tag.txt) 五、 去掉双引号-F”\””，并去掉换行符printf awk -F”\”” ‘{printf $2 $3}’ 91130606700751737C_tag.txt 六、 过滤掉一部分数据，如过滤包含”高”，”区”，”都”，”这”的词条，这个是在未取消换行的时候执行的 awk ‘{if(!($0~/高|区|都|这/)) print $0}’ 91130606700751737C_tag.txt 或 awk ‘{if($0!~/高|区|都|这/) print $0}’ awkt2.txt]]></content>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch中文全文检索]]></title>
    <url>%2F2018%2F08%2F08%2Felasticsearch-fulltext-01%2F</url>
    <content type="text"><![CDATA[前提：安装好ik-analyze 1. 创建index1curl -XPUT http://localhost:9200/poetry 查询索引：1curl -XGET http://localhost:9200/indices 查询结果：12hexin@hexin:~/test/es$ curl localhost:9200/_cat/indices?prettygreen open poetry XxSNsdRLSxifRwg22Ezn6Q 5 1 0 0 810b 324b 2. 创建type的mapping。查看index（或者map下面的type）的mapping123456789101112curl -XPOST http://localhost:9200/poetry/fulltext/_mapping -H &apos;Content-Type:application/json&apos; -d&apos;&#123; &quot;properties&quot;: &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; &#125; &#125;&#125;&apos; 查看映射1curl localhost:9200/poetry/_mapping?pretty 查询结果 1234567891011121314&#123; &quot;poetry&quot; : &#123; &quot;mappings&quot; : &#123; &quot;fulltext&quot; : &#123; &quot;properties&quot; : &#123; &quot;content&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;ik_max_word&quot; &#125; &#125; &#125; &#125; &#125;&#125; 3. 插入数据12345678910111213141516171819curl -XPOST http://localhost:9200/poetry/fulltext/1 -H &apos;Content-Type:application/json&apos; -d&apos;&#123;&quot;content&quot;:&quot;轻轻的我走了，正如我轻轻的来&quot;&#125;&apos;curl -XPOST http://localhost:9200/poetry/fulltext/2 -H &apos;Content-Type:application/json&apos; -d&apos;&#123;&quot;content&quot;:&quot;我轻轻的招手，作别西天的云彩&quot;&#125;&apos;curl -XPOST http://localhost:9200/poetry/fulltext/3 -H &apos;Content-Type:application/json&apos; -d&apos;&#123;&quot;content&quot;:&quot;那河畔的金柳，是夕阳中的新娘&quot;&#125;&apos;curl -XPOST http://localhost:9200/poetry/fulltext/4 -H &apos;Content-Type:application/json&apos; -d&apos;&#123;&quot;content&quot;:&quot;波光里的艳影，在我的心头荡漾&quot;&#125;&apos;curl -XPOST http://localhost:9200/poetry/fulltext/5 -H &apos;Content-Type:application/json&apos; -d&apos;&#123;&quot;content&quot;:&quot;在康河的柔波里，我甘心做一条水草&quot;&#125;&apos; 4. 测试分词123456curl -X GET &quot;localhost:9200/poetry/_analyze?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;field&quot;: &quot;content&quot;, &quot;text&quot;: &quot;曾经沧海难为水，除却巫山不是云&quot; &#125;&apos; 结果：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;曾经沧海难为水&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;曾经沧海&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;曾经&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;沧海&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;海难&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;难为&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;水&quot;, &quot;start_offset&quot; : 6, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 6 &#125;, &#123; &quot;token&quot; : &quot;除却巫山不是云&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 15, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 7 &#125;, &#123; &quot;token&quot; : &quot;除却&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 10, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 8 &#125;, &#123; &quot;token&quot; : &quot;巫山&quot;, &quot;start_offset&quot; : 10, &quot;end_offset&quot; : 12, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 9 &#125;, &#123; &quot;token&quot; : &quot;不是&quot;, &quot;start_offset&quot; : 12, &quot;end_offset&quot; : 14, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 10 &#125;, &#123; &quot;token&quot; : &quot;云&quot;, &quot;start_offset&quot; : 14, &quot;end_offset&quot; : 15, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 11 &#125; ]&#125; 5. 检索数据 4.1 简单检索 curl localhost:9200/poetry/_search?pretty 4.2 全文检索 123456789101112curl -XPOST http://localhost:9200/poetry/fulltext/_search?pretty -H &apos;Content-Type:application/json&apos; -d&apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;content&quot; : &quot;轻轻&quot; &#125;&#125;, &quot;highlight&quot; : &#123; &quot;pre_tags&quot; : [&quot;&lt;tag1&gt;&quot;, &quot;&lt;tag2&gt;&quot;], &quot;post_tags&quot; : [&quot;&lt;/tag1&gt;&quot;, &quot;&lt;/tag2&gt;&quot;], &quot;fields&quot; : &#123; &quot;content&quot; : &#123;&#125; &#125; &#125;&#125;&apos; 4.2 聚合查询]]></content>
  </entry>
  <entry>
    <title><![CDATA[将MongoDB数据加载到Elasticsearch]]></title>
    <url>%2F2018%2F08%2F03%2Ftransport-data-from-mongo-to-es%2F</url>
    <content type="text"><![CDATA[一、前言 由于业务需要，需要将放在MongoDB的数据加载到Elasticsearch，Elasticsearch天生具有全文检索优势。MongoDB虽然新的版本也支持fulltext，但目前尚未支持中文。所以这里我们就用比较流行的Elasticsearch。另外，为了方便，我会基于Docker搭建MongoDB和Elasticsearch集群 二、docker的安装和使用环境：Ubuntu 16.04.5 LTS 2.1 如果存在旧版本docker，先删除旧版本$ sudo apt-get remove docker docker-engine docker.io 2.2 更新apt-get$sudo apt-get update 2.3 添加docker官方 GPG key123456$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -$ sudo apt-key fingerprint 0EBFCD88pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &lt;docker@docker.com&gt;sub 4096R/F273FCD8 2017-02-22 2.4 安装docker $ sudo apt-get install docker-ce 至此，docker已经安装完成，直接输入docker命令可查看docker的帮助，如命令docker version查看docker版本信息 参考：https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-docker-ce-1 三、搭建MongoDB服务这里我们就直接使用docker仓库的mongodb镜像。 3.1 查询mongodb镜像jogen@mymachine:~/test/es$ docker search mongoNAME DESCRIPTION STARS OFFICIAL AUTOMATEDmongo MongoDB document databases provide high avai… 4773 [OK]mongo-express Web-based MongoDB admin interface, written w… 274 [OK] 3.2 docker pull拉取镜像$docker pull mongo 3.3 从docker镜像安装mongo docker run –name mongodb2 -p 27018:27017 -d mongo –replSet mongoReplSet–replSet：添加复制集查看复制机状态：rs.status()查看配置：rs.conf()初始化：rs.initiate()修改配置：rs.reconfig(cfg),具体使用可以查看官网文档，我们这里会修改主机名为ip地址。 3.4 使用mongodb-compassmongodb-compass：是mongodb的可视化工具，访问mongodb比较方便，这里使用到了它的数据导入导出功能，该工具比较方便。当然RobotT3也比较好用，但是我找不到数据导入导出功能。 3.5 建立database和collection，并导入一些数据。四、搭建Elastisearch集群服务4.1 查询镜像 docker search elastisearch 4.2 拉取镜像到本地 docker pull docker.elastic.co/elasticsearch/elasticsearch:5.6.10 docker官方中央仓库维护的es已经不再维护，elastic已经自己建立了自己的私有库，并维护。 docker官方仓库的elastic镜像地址：https://hub.docker.com/_/elasticsearch/, elastic6版本之后的，都放在elastic自己的docker仓库维护了。elastic的仓库是：https://www.docker.elastic.co/ 4.3 使用安装docker-compose123sudo curl -L https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose$ docker-compose --version 参考：https://docs.docker.com/compose/install/#install-compose 4.4 创建docker-compose.yml文件本地新建一个目录，如elastictest，存放自己的项目项目信息，docker-compose.yml也放在里面，其内容：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version: &apos;2&apos;services: elasticsearch1: image: docker.elastic.co/elasticsearch/elasticsearch:5.6.10 container_name: elasticsearch1 environment: - cluster.name=docker-cluster - xpack.security.enabled=false - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 mem_limit: 1g volumes: - esdata1:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - esnet elasticsearch2: image: docker.elastic.co/elasticsearch/elasticsearch:5.6.10 environment: - cluster.name=docker-cluster - xpack.security.enabled=false - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - &quot;discovery.zen.ping.unicast.hosts=elasticsearch1&quot; ulimits: memlock: soft: -1 hard: -1 mem_limit: 1g volumes: - esdata2:/usr/share/elasticsearch/data networks: - esnetvolumes: esdata1: driver: local esdata2: driver: localnetworks: esnet: 说明： - xpack.security.enabled=false 配置这个，是因为docker中的elasticsearch默认安装了x-path插件，该插件在我们访问es时需要输入账号密码（默认是elastic/changeme），在数据同步的时候可能会比较麻烦. 4.5 启动服务docker-compose up 4.6 安装elasticsearch-head扩展插件ElasticSearch-Head插件有助于查看和管理es集群，有多种安装方式，可以参考：https://github.com/mobz/elasticsearch-head我这里是使用chrome扩展方式，比较方便。进入chrome的Web-store，搜索ElasticSearch Head并安装 4.7 访问集群es集群启动好之后，通过head插件访问结果如下： 五、使用Transporter传输数据现在MongoDB和ES集群都已经启动起来了，接下来就是数据同步的问题，从MongoDB到ElasticSearch的同步有多种方式： 1. mongo-connector： 2. logstach 3. Transporter 4. elasticsearch-river-mongodb 5. Mongoosastic 具体的区别可参考：https://code.likeagirl.io/5-different-ways-to-synchronize-data-from-mongodb-to-elasticsearch-d8456b83d44f一开始，我使用的是mongo-connector方式，但只支持es5.x版本，到目前位置，尚未支持es6.x。一个原因可能是es更新太快，mongo-connector已经力不从心。我们从github上看到，已经半年没有更新了，一个致命的点就是跟es的版本强相关。所以我上面docker镜像也是使用的5.x版本的原因。其实目前es已经到6.3.2版本了。此外，在使用mongo-connector过程中，需要用到elastic2_doc_manager中间组件，运行时经常同步不了数据，一运行同步程序，就卡主，没有任何日志输出。这让人难以接受。于是就想尝试使用tansporter。 transporter的使用参考：https://github.com/compose/transporter这里列出主要步骤： 下载transporter客户端https://github.com/compose/transporter/releases/download/v0.5.2/transporter-0.5.2-linux-amd64添加执行权限：chmod +x transporter-0.5.2-linux-amd64修改名称：mv transporter-0.5.2-linux-amd64 transporter发送到、/usr/bin 目录，以供全局使用：mv transporter /usr/bin transporter初始化在项目目录elastictest执行：transporter init mongodb elasticsearch执行完后，在本地生成一个pipline.js文件，文件内容： 12345678910111213141516171819202122var source = mongodb(&#123; &quot;uri&quot;: &quot;mongodb://127.0.0.1:27017/enterprise&quot; // &quot;timeout&quot;: &quot;30s&quot;, // &quot;tail&quot;: false, // &quot;ssl&quot;: false, // &quot;cacerts&quot;: [&quot;/path/to/cert.pem&quot;], // &quot;wc&quot;: 1, // &quot;fsync&quot;: false, // &quot;bulk&quot;: false, // &quot;collection_filters&quot;: &quot;&#123;&#125;&quot;, // &quot;read_preference&quot;: &quot;Primary&quot;&#125;)var sink = elasticsearch(&#123; &quot;uri&quot;: &quot;http://localhost:9200/enterprise&quot; // &quot;timeout&quot;: &quot;10s&quot;, // defaults to 30s // &quot;aws_access_key&quot;: &quot;ABCDEF&quot;, // used for signing requests to AWS Elasticsearch service // &quot;aws_access_secret&quot;: &quot;ABCDEF&quot; // used for signing requests to AWS Elasticsearch service // &quot;parent_id&quot;: &quot;elastic_parent&quot; // defaults to &quot;elastic_parent&quot; parent identifier for Elasticsearch&#125;)t.Source(&quot;source&quot;, source, &quot;/.*/&quot;).Save(&quot;sink&quot;, sink, &quot;/.*/&quot;) 住需要修改两个地方的uri，这里我已经修改了。 执行数据同步transporter run到此数据同步完成，可以开心地打开head扩展插件查看同步结果了。 可以参考：https://aboullaite.me/sync-data-from-mongodb-to-elasticsearch-using-transporter/ 六、总结在实践过程中还是需要多尝试，使用mongo-connector的过程中，甚至出现需要去直接修改源码的情况，比如请求过程中的headers缺少了Content-Type，需要手动添加进去。]]></content>
      <tags>
        <tag>MongoDB,Docker,Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用ssh-keygen实现免密登录服务器]]></title>
    <url>%2F2018%2F07%2F26%2Fssh-keygen%2F</url>
    <content type="text"><![CDATA[参考：https://www.cnblogs.com/dream-to-pku/p/7049760.html 一、目标：免密登陆服务器有两台服务器，分别为web12和web13，需要实现web12免密码登录web1312192.168.1.12 web12192.168.1.13 web13 二、生成公钥私钥对web12在用户（假设为root）目录下执行命令: ssh-keygen -t rsa, 或者直接执行ssh-keygen命令（默认使用的也是rsa加密类型）。此时会在当前目录下生成.ssh文件夹，里面有公钥（id_rsa.pub）和秘钥(id_rsa) 三、在web13上也用同样的方式生成公钥和秘钥四、修改配置文件在web13上，查看/etc/ssh/sshd_config文件，找到： AuthorizedKeysFile .ssh/authorized_keys 如果没有需要加上。 五、提交公钥到服务器web12上执行：123cat id_rsa.pub &gt;&gt; authorized_keys #把公钥复制到文件authorized_keys中chmod 600 authorized_keys #修改文件权限，否则可能会无法登录scp authorized_keys root@45.77.43.6:/root/.ssh/ #将web12上生成的公钥信息拷贝到主服务器上，主服务器配置了sshd_config，认证文件指向了authorized_keys文件。 六、执行免密登陆在web12上执行： ssh root@45.77.43.6 验证是否已经实现了免密登录，正常来说是可以了的。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在CentOS安装google-chrome]]></title>
    <url>%2F2018%2F07%2F25%2Fcentos-google-chrome%2F</url>
    <content type="text"><![CDATA[一、写这篇文章的原因最近在写爬虫，需要解析动态页面数据，不能够直接请求接口，接口有经过复杂的加密。解析动态页面需要用到浏览器的支持，有三个浏览器可以使用：chromefirefoxPhantomJS由于firefox解析的时候，部分页面没有会乱，如在获取验证码的位置时获取不到，而验证码的页面是嵌套在iframe下面的。而PhantomJS已经不再支持，官方建议使用chrome和firefox。基于以上情况，我选择使用google的chrome无头浏览器。 二、google-chrome无头浏览器使用参考：https://developers.google.com/web/updates/2017/04/headless-chrome 三、google-chrome的安装由于爬虫应用需要放在CentOS服务器上，因此需要在CentOS安装google-chrome。安装过程参考配置yum源 在/etc/apt/sources.list加上deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main 执行wget https://dl.google.com/linux/linux_signing_key.pub 执行sudo apt-key add linux_signing_key.pub 执行 sudo apt update sudo apt install google-chrome-stable 参考：https://www.linuxbabe.com/ubuntu/install-google-chrome-ubuntu-16-04-lts 四、报错：1234567891011121314Transaction Summary===================================================================================================================Install 1 Package (+37 Dependent packages)Total size: 71 MInstalled size: 236 MIs this ok [y/d/N]: yDownloading packages:warning: /var/cache/yum/x86_64/7/google-chrome/packages/google-chrome-stable-67.0.3396.99-1.x86_64.rpm: Header V4 DSA/SHA1 Signature, key ID 7fac5991: NOKEYRetrieving key from https://dl-ssl.google.com/linux/linux_signing_key.pubGPG key retrieval failed: [Errno 14] curl#7 - "Failed to connect to 2404:6800:4008:c02::be: Network is unreachable"[root@reptile v2ray]# 通过报错信息，我们知道是无法下载 https://dl-ssl.google.com/linux/linux_signing_key.pub文件，我们的CentOS是没有做翻墙的，所以无法安装。解决办法 需要先在可以翻墙的机器（我本地开发机就安装了ssr翻墙）下载这个文件，然后再scp拷贝到我们的服务器上。 wget https://dl-ssl.google.com/linux/linux_signing_key.pub 拷贝到CentOS后，执行如下命令。 rpm –import linux_signing_key.pub 校验是否已经正确import rpm -qi gpg-pubkey-7fac5991-* 参考：https://blog.csdn.net/knityster/article/details/6312498 到此准备工作已经完成 五、正式安装，执行命令yum install -y google-chrome-stable 安装完成后，校验是否安装成功： google-chrome –no-sandbox –headless –disable-gpu –screenshot https://www.baidu.com 执行完后，在当前目录生成一个png文件。就是baidu首页的截图 六、其他：安装firefox无头浏览器参考：https://developer.mozilla.org/en-US/Firefox/Headless_mode]]></content>
      <tags>
        <tag>google-chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-logic-graph]]></title>
    <url>%2F2018%2F04%2F05%2Fmysql-logic-graph%2F</url>
    <content type="text"><![CDATA[逻辑架构图 MySQL的逻辑架构大致可以分为三层； 第一层：客户端层连接处理、授权认证、安全 第二层：核心服务查询解析、分析、优化、缓存以及所有的内置函数（例如，日期、时间、数学和加密函数），所有跨存储引擎的功能都在这一层实现：视图、触发器、储存过程等。 第三层：存储引擎存储引擎负责 MySQL 中数据的存储和提取，不同存储引擎之间不会相互通信。 并发控制读写锁锁类型：（Shared Lock）共享锁和（Exclusive Lock）排他锁。 共享锁也叫（Read Lock）读锁，排他锁也叫（Write Lock）写锁。 锁粒度（table lock）表锁和（row lock）行锁。 事务数据库事务的ACID特性 原子性（atomicity） 一致性(consistency) 隔离性(isolation) 持久性(durability) 数据库事务的隔离级别 READ UNCOMMITED (未提交读) READ COMMITED (提交读)；Oracle默认事务隔离级别 REPEATABLE READ (可重复读)；MySQL默认事务隔离级别 SERIALIZABLE (可串行化) 死锁什么时候会发生死锁： 当多个事务试图以不同的顺序锁定资源时，就可能会产生死锁； 多个事务同时锁定统一资源时，也会产生死锁。 处理办法： 死锁检测；数据库系统实现了各种死锁检测和死锁超时机制。 InnoDB处理死锁方式:将持有最少行级排它锁的事务进行回滚。 锁的行为和顺序是和存储引擎相关的。 多并发版本控制MySQL的大多数存储引擎实现的都不是简单的行级锁。基于提升并发性能的思考，他们一般实现了多版本并发控制（MVCC）。 InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现的。 MySQL存储引擎常用的有两个 InnoDB 存储引擎 MyISAM 存储引擎。MySQL5.1 及之前的版本，MyISAM是默认的存储引擎。 MyISAM 特点：提供全文索引、压缩、空间函数（GIS）等；不支持事务和行级锁；崩溃后无法安全恢复。 其他内建存储引擎：Archive、Blackhole、Federated、Memory、Merge、NDB等第三方存储引擎：OLTP类引擎、面向列的存储引擎、社区存储引擎]]></content>
  </entry>
  <entry>
    <title><![CDATA[memcached的安装和使用（单点）]]></title>
    <url>%2F2017%2F07%2F22%2Fmemcached%2F</url>
    <content type="text"><![CDATA[Linux安装memcached 一、Memcached的安装：使用命令安装 使用命令安装安装时，会自动安装memcached的依赖libevent。libevent是memcached的通信模块。 1yum install memcached 启动memcached服务安装完成后，可以使用find / -name memcached命令查询memcached存放的目录。 1234[root@izwz96tljwj636zfkf3wvqz ~]# find / -name memcached/etc/selinux/targeted/active/modules/100/memcached/etc/sysconfig/memcached/usr/bin/memcached memcached命令放在/usr/bin/目录下面，cd到/usr/bin目录，执行启动memcached服务命令1memcached -d -m 512 -u root -p 11211 -c 10000 -M -f 1.1 -P /tmp/memcached.pid 启动成功后，就可以在window上面telnet ip 11211测试是否可以使用了。 启动memcached1234[root@localhost ~]# memcached -d -m 10 -u root -l 192.168.1.75 -p 11212 -c 256 -P /tmp/memcached.pid[root@localhost ~]# ps -ef|grep memcachedmemcached -d -m 10 -u root -l 39.108.10.27 -p 11212 -c 256 -P /tmp/memcached.pid 二、memcached的使用 配置连接信息在属性文件sys.properties中配置memcached的连接信息;如果是集群方式，这配置多个服务连接信息 1234567891011121314151617#memcached# the pool size(the number of client)memcached.connectionPoolSize=5# in this mode, when a node out, it will throws MemcachedException when call this nodememcached.failureMode=true#server1memcached.server1.host=39.108.10.27memcached.server1.port=11211memcached.server1.weight=1#server2#memcached.server2.host=192.168.88.141#memcached.server2.port=11211#memcached.server2.weight=1#server3#memcached.server3.host=192.168.88.142#memcached.server3.port=11211#memcached.server3.weight=1 在config-cache.xml的spring配置文件中配置memcached客户端构建器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;!--memcached配置开始--&gt; &lt;bean id="memcachedClientBuilder" class="net.rubyeye.xmemcached.XMemcachedClientBuilder"&gt; &lt;!-- XMemcachedClientBuilder have two arguments.First is server list,and second is weights array. --&gt; &lt;property name="connectionPoolSize" value="$&#123;memcached.connectionPoolSize&#125;"/&gt; &lt;property name="failureMode" value="$&#123;memcached.failureMode&#125;"/&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;bean class="java.net.InetSocketAddress"&gt; &lt;constructor-arg&gt; &lt;value&gt;$&#123;memcached.server1.host&#125;&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;$&#123;memcached.server1.port&#125;&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- &lt;bean class="java.net.InetSocketAddress"&gt; &lt;constructor-arg&gt; &lt;value&gt;$&#123;memcached.server2.host&#125;&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;$&#123;memcached.server2.port&#125;&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="java.net.InetSocketAddress"&gt; &lt;constructor-arg&gt; &lt;value&gt;$&#123;memcached.server3.host&#125;&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;$&#123;memcached.server3.port&#125;&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; --&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;value&gt;$&#123;memcached.server1.weight&#125;&lt;/value&gt; &lt;!--&lt;value&gt;$&#123;memcached.server2.weight&#125;&lt;/value&gt;--&gt; &lt;!--&lt;value&gt;$&#123;memcached.server3.weight&#125;&lt;/value&gt;--&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;!-- BinaryCommandFactory --&gt; &lt;property name="commandFactory"&gt; &lt;bean class="net.rubyeye.xmemcached.command.BinaryCommandFactory" /&gt; &lt;/property&gt; &lt;property name="transcoder"&gt; &lt;bean class="net.rubyeye.xmemcached.transcoders.SerializingTranscoder" /&gt; &lt;/property&gt; &lt;property name="bufferAllocator"&gt; &lt;bean class="net.rubyeye.xmemcached.buffer.SimpleBufferAllocator"&gt;&lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- Use factory bean to build memcached client --&gt; &lt;bean id="memcachedClient" factory-bean="memcachedClientBuilder" factory-method="build" destroy-method="shutdown" /&gt; &lt;!--memcached配置结束--&gt; 在java代码中使用 123456//注入客户端@Resourceprivate MemcachedClient memcachedClient; //在方法中使用(对缓存执行增删改查) memcachedClient.delete(DOMAIN_TREE_ROOT_KEY);]]></content>
  </entry>
  <entry>
    <title><![CDATA[在mac上开发ionic项目]]></title>
    <url>%2F2017%2F07%2F14%2Fionic01%2F</url>
    <content type="text"><![CDATA[1. 环境准备npm install -g cordova ionic配置android sdk和java环境变量1234567891011~$cat ./.bash_profileJAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/HomeANDROID_HOME=/Users/wukangjie/Library/Android/sdkM2_HOME=/Users/wukangjie/Documents/apache-maven-3.5.0PATH=$JAVA_HOME/bin:$PATH:.:$M2_HOME/bin:$ANDROID_HOME/platform-tools:$ANDROID_HOME/toolsCLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:.export JAVA_HOMEexport ANDROID_HOMEexport PATHexport CLASSPATexport M2_HOME 2. 创建ionic应用ionic start myApp tabs 3. 启动应用cd myAppionic serve 4. 添加ionic的ios运行平台city_operation_app$ionic platform add iosThe platform command has been renamed. To find out more, run: ionic cordova platform –help city_operation_app$ionic cordova platform –help解决办法：实用命令ionic cordova platfrom add ios 如果是添加android平台运行 ionic cordova platform add 这时会有提示，选择ios或者android 或者直接运行 ionic cordova platform add andriod 跑完上面的命令，会在项目下面自动新增一个platform目录，下面有对于端ios目录和android目录。 5. 构建项目ionic cordova build ios 6. 运行项目cordova emulate ios –target=”iPhone-6” 安装highchartscity_operation_app$typings install dt~highcharts –save –globalhighcharts 7. 集成highcharts 7.1 安装highcharts npm install highcharts –save 7.2 安装ng-highcharts npm install ng-higcharts –save 7.3 在ts文件中引入 import * as Highcharts from ‘highcharts’; 7.4使用1234567891011121314151617181920212223242526@ViewChild('chart') public chart: ElementRef;ionViewDidEnter() &#123; Highcharts.chart('tourism1', &#123; chart: &#123; type: 'bar' &#125;, title: &#123; text: 'Fruit Consumption' &#125;, xAxis: &#123; categories: ['Apples', 'Bananas', 'Oranges'] &#125;, yAxis: &#123; title: &#123; text: 'Fruit eaten' &#125; &#125;, series: [&#123; name: 'Jane', data: [1, 0, 4] &#125;, &#123; name: 'John', data: [5, 7, 3] &#125;] &#125;);&#125; 8 集成chart8.1 安装组件 npm install –save chart.js 8.2 在ts文件中引入 import * as ChartJs from ‘chart.js’; 在ts文件中实用12345678910111213141516171819202122232425262728293031323334353637383940getlivelihoodRate() &#123; var canvas = &lt;HTMLCanvasElement&gt; document.getElementById(&quot;myChart&quot;); var ctx = canvas.getContext(&quot;2d&quot;); // 这里是关键, 不能写在constructor()中 new ChartJs(ctx, &#123; type: &apos;bar&apos;, data: &#123; labels: [&quot;Red&quot;, &quot;Blue&quot;, &quot;Yellow&quot;, &quot;Green&quot;, &quot;Purple&quot;, &quot;Orange&quot;], datasets: [&#123; label: &apos;# of Votes&apos;, data: [12, 19, 3, 5, 2, 3], backgroundColor: [ &apos;rgba(255, 99, 132, 0.2)&apos;, &apos;rgba(54, 162, 235, 0.2)&apos;, &apos;rgba(255, 206, 86, 0.2)&apos;, &apos;rgba(75, 192, 192, 0.2)&apos;, &apos;rgba(153, 102, 255, 0.2)&apos;, &apos;rgba(255, 159, 64, 0.2)&apos; ], borderColor: [ &apos;rgba(255,99,132,1)&apos;, &apos;rgba(54, 162, 235, 1)&apos;, &apos;rgba(255, 206, 86, 1)&apos;, &apos;rgba(75, 192, 192, 1)&apos;, &apos;rgba(153, 102, 255, 1)&apos;, &apos;rgba(255, 159, 64, 1)&apos; ], borderWidth: 1 &#125;] &#125;, options: &#123; scales: &#123; yAxes: [&#123; ticks: &#123; beginAtZero: true &#125; &#125;] &#125; &#125; &#125;)&#125; 8.4 html文件中编写图表元素1&lt;canvas id=&quot;myChart&quot; width=&quot;60%&quot; height=&quot;60%&quot;&gt;&lt;/canvas&gt; 9 添加导航，并返回点击按钮，打开一个新页面，新页面带有“返回”按钮。最直接的方式是参考官方文档。9.1 写好跳转后的页面，入详情页面9.2 引入detail页面 import { PopulationDetailPage } from ‘./sub/population_detail’;9.3 在home.ts中写点击事件处理方法123openNavDetailsPage(item) &#123; this.nav.push(PopulationDetailPage, &#123; item:item &#125;);&#125; 9.4 在appModule中声明12345678910111213import &#123; PopulationDetailPage&#125; from &apos;../pages/home/sub/population_detail&apos;;@NgModule(&#123; declarations: [ MyApp, ... PopulationDetailPage ], entryComponents: [ MyApp, ... PopulationDetailPage ],&#125;) 9.5 修改返回按钮的文字：从BACK变为中文的“返回” 也是在appModule中修改12345678imports: [ BrowserModule, HttpModule, JsonpModule, IonicModule.forRoot(MyApp, &#123; backButtonText: &apos;返回&apos;, &#125;) ],]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用vps搭建翻墙服务，实现科学上网]]></title>
    <url>%2F2017%2F05%2F29%2Fvps%2F</url>
    <content type="text"><![CDATA[用过当前市面上比较流行的翻墙工具，比如lantern、loco加速器。但都比较贵，一个月好几十块钱，有时还不是很稳定，于是就想自己租用一个外地服务器，实现科学上网，这里使用的是vultr服务器搭建翻墙 一、在https://www.vultr.com/购买服务器 注册账号 注册一个vultr账号，登录vultr 购买服务器 使用paypal支付 paypal账号 如果还没有paypal账号支付，就去注册一个，并关联信用卡。不然无法支付。 查看服务器信息，并使用xshell连接 二、 安装ssrssr，也就是翻墙使用的服务器端的软件。比较常用的是shadowsocks。1wget --no-check-certificate https://www.qcgzxw.cn/SSR/shadowsocksR.sh; bash shadowsocksR.sh 安装成功123456789101112祝贺！ ShadowsocksR 已经配置成功!服务器 IP: 45.32.XXX.XXX 服务器 端口: 8989 连接密码: yourpwd123协议: auth_sha1_v4 obfs: tls1.2_ticket_auth 加密方式: chacha20 多用户配置方式:https://www.qcgzxw.cn/?p=533如果您想更改连接协议或者加密方式 请前往：https://www.qcgzxw.cn/?p=533Enjoy it! 注意，安装完成后，默认的加密方式是chacha20.后面连接不了，就是因为这个加密方式的问题，后面需要改成aes-256-cfb.再重新连接就可以了。 三、安装锐速安装脚本1wget -N --no-check-certificate https://github.com/91yun/serverspeeder/raw/master/serverspeeder-v.sh &amp;&amp; bash serverspeeder-v.sh CentOS 7.2 3.10.0-327.el7.x86_64 x64 3.11.20.5 serverspeeder_72327 如果安装失败，https://www.91yun.org/serverspeeder91yun 找到合适的版本。不同的系统安装的时候是不同的脚本的。 安装成功提示123456789101112131415161718192021===============System Info=======================CentOS 3.10.0-514.16.1.el7.x86_64 x64 =================================================installing ServerSpeeder, please wait for a moment...[Running Status]ServerSpeeder is NOT running!version 3.11.20.5[License Information]License 607CDDB633476C89 (valid on current device)MaxSession unlimitedMaxTcpAccSession unlimitedMaxBandwidth(kbps) unlimitedExpireDate 2034-12-31[root@vultr ~]# 四、安装shadowsocks连接客户端已经启动了shadowsocks，但是访问 google.com出现错误1234567504 Connect to google.com:80 failed: SOCKS protocol errorThe following error occurred while trying to access http://google.com/:504 Connect to google.com:80 failed: SOCKS protocol errorGenerated Sun, 28 May 2017 12:19:48 中国标准时间 by Polipo on Lenovo-PC:8123. 解决办法：就是那个连接方式的问题，加密方式由默认的chacha20改成aes-256-cfb。重启shadowsocks，重新连接就可以了。 五、 重启shadowsocks服务重启之前，先使用ps -ef|grep shadowsocks查看已经启用的进程，再kill -9 pid杀掉进程，重启即可。 1python /usr/local/shadowsocks/shadowsocks/server.py -c /etc/shadowsocks.json -d start 六、参考地址 注册vulter，租用服务器，类似于国内的阿里云：https://my.vultr.com/ 注册paypal账号并绑定信用卡：https://www.paypal.com/signin 安装shadowsocks教程：https://www.qcgzxw.cn shadowsocks文档和下载：https://github.com/shadowsocks/shadowsocks-windows shadowsocks客户端：https://github.com/shadowsocks/shadowsocks-qt5 。也可以不用这个 锐速安装地址：https://www.91yun.org/serverspeeder91yun 七、特别提醒安装完ssr后，记得修改加密方式为aes-256-cfb。并重启服务。这个很重要。]]></content>
      <tags>
        <tag>翻墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat内存溢出PerGen space]]></title>
    <url>%2F2017%2F05%2F18%2Foom01%2F</url>
    <content type="text"><![CDATA[一、应用在tomcat运行一段时间后，出现内存溢出报错。如永久区内存溢出PermGen space; 12345678910111213141516172017-5-18 14:56:01 org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler process严重: Error reading request, ignoredjava.lang.OutOfMemoryError: PermGen space at java.lang.Throwable.getStackTraceElement(Native Method) at java.lang.Throwable.getOurStackTrace(Throwable.java:591) at java.lang.Throwable.printStackTrace(Throwable.java:510) at java.util.logging.SimpleFormatter.format(SimpleFormatter.java:72) at org.apache.juli.FileHandler.publish(FileHandler.java:198) at java.util.logging.Logger.log(Logger.java:478) at java.util.logging.Logger.doLog(Logger.java:500) at java.util.logging.Logger.logp(Logger.java:700) at org.apache.juli.logging.DirectJDKLog.log(DirectJDKLog.java:167) at org.apache.juli.logging.DirectJDKLog.error(DirectJDKLog.java:135) at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:875) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:620) at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) at java.lang.Thread.run(Thread.java:662) 二、原因分析： 查看应用运行分配的内存情况12[testapp@zhmgr-002 microactivitymgr]$ jps -lv|grep activity13046 org.apache.catalina.startup.Bootstrap -Xms512m -Xmx1024m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -Djava.util.logging.config.file=/data/tomcat6-microactivitymgr/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/data/tomcat6-microactivitymgr/endorsed -Dcatalina.base=/data/tomcat6-microactivitymgr -Dcatalina.home=/data/tomcat6-microactivitymgr -Djava.io.tmpdir=/data/tomcat6-microactivitymgr/temp 发现只对堆内存设置了内存-Xms512m -Xmx1024m，永久区并没有设置（XX参数）。 查看该应用的内存使用情况123$&gt;jstat -gcutil 13046 S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 0.00 0.00 5.83 100.00 54 0.264 2174 515.817 516.081 三、 解决办法：加大永久区的内存配置方法：在之前的加大堆方法的后面加上： -XX:MaxNewSize=256m -XX:MaxPermSize=256m 重启即可]]></content>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis安装]]></title>
    <url>%2F2017%2F05%2F18%2Finstall-redis%2F</url>
    <content type="text"><![CDATA[按照官网的安装流程就行安装 一、执行make命令,报错1234567[root@nq-sz-kf001-01 src]# make CC adlist.oIn file included from adlist.c:34:zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directoryzmalloc.h:55:2: error: #error "Newer version of jemalloc required"make: *** [adlist.o] Error 1[root@nq-sz-kf001-01 src]# 二、 报错处理：没有gcc安装过程12345678yum install cppyum install binutilsyum install glibcyum install glibc-kernheadersyum install glibc-commonyum install glibc-develyum install gccyum install make 注意gcc依赖了很多东西，有些包可能系统已经 装了，有些没有，防止出意外，最好都走一遍 ############解决方法#############make MALLOC=libc 三、window下安装1、下载地址https://github.com/dmajkic/redis/downloads2、打开一个cmd窗口，使用cd命令切换到指定目录（D:\redis\64bit）运行 redis-server.exe redis.conf 。运行以后出现如下界面 四、测试Redis服务端是否已经安装成功 cmd到D:\redis\64bit,运行 redis-cli.exe -h 127.0.0.1 -p 6379 其中 127.0.0.1是本地ip，6379是redis服务端的默认端口 测试12set test "11111111111111111"get test]]></content>
      <categories>
        <category>数据存储</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境：内存溢出]]></title>
    <url>%2F2017%2F05%2F18%2Flinux-shell-02%2F</url>
    <content type="text"><![CDATA[有时候在linux环境下tomcat内存不够，需要手动增加内存的配置 vim ./catalina.sh 大概在375行只需要新增添加的部分1-Xms1024m -Xmx1024m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境：tomcat统一启动脚本]]></title>
    <url>%2F2017%2F05%2F18%2Flinux-shell-01%2F</url>
    <content type="text"><![CDATA[如果linux服务器安装了很多tomcat应用，有时候需要单独重启某一个tomcat的应用，这时候，如果每次操作都需要进入到tomcat的bin目录下面去执行shutdown.sh和startup.sh，这将是非常麻烦的事情。所以就写了一个脚本，以便在shell中任何位置都可以重启指定的tomcat。 一、在/usr/scripts/下面脚本文件restartpro.sh内容1234567891011121314if [ -z "$1" ]; then echo "脚本执行方法： restartpro 程序名" exitfisource /etc/profileps -ef|grep tomcat6-$1|grep -v tomcat6-$1-|awk '&#123;print $2&#125;'|xargs kill -9cd /data/tomcat6-$1/conf/Catalinarm -rf localhostcd /data/tomcat6-$1/work/Catalinarm -rf localhost logscd /data/tomcat6-$1/logsrm -rf *.log* *.out/data/tomcat6-$1/bin/startup.shtail -f /data/tomcat6-$1/logs/*.out 二、在/etc/profile文件最后一行添加12alias restartpro='/usr/scripts/restartpro.sh'#alias restartpro7='/usr/scripts/restartpro7.sh' 三、重启tomcat假设我们有三个tomcat，分别放在/data/下面，名字为 tomcat-A tomcat-B tomcat-C那么我现在需要重启tomcat-B，直接就可以在shell中执行 $&gt;restartpro B 注：不需要tomcat，可以通过脚本可以看得出。脚本会自动给咱们加上tomcat-]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用DataGrip通过ssl方式连接MySQL数据库]]></title>
    <url>%2F2017%2F05%2F18%2Fssl-mysql%2F</url>
    <content type="text"><![CDATA[以前一直使用navicat连接mysql，虽然也特别好用，功能强大，但是这个工具经常卡死无法响应。后面在使用Intellij IDEA的过程中，在它官网就发现了DataGrip，发现这个工具比较好用，自动提示也非常好。下面就简单介绍一下这个工具如何通过ssl方式连接MySQL，当然navicat也是可以使用ssl连接的。 一、 ssl连接准备平时我们直接连接使用工具连接mysql的时候，直接输入IP、端口、用户名和密码登录。但是使用ssl登录的时候，需要额外得做个简单配置，准备文件有： client-cert.pem client-no-password-key.pem mysql-ca-cert.pem 二、 连接mysql 正常连接，输入IP、端口、用户名和密码 使用ssl连接 三、总结， 需要准备ssl连接文件 ssl连接文件路径不能有中文字符]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用powerdesigner反向工程生成数据表的测试数据]]></title>
    <url>%2F2017%2F05%2F13%2Fgenerate-test-data-by-powerdesigner%2F</url>
    <content type="text"><![CDATA[前几天在搞一个项目，对接接口的时候发现没有测试数据。通过系统新增测试数据固然是比较正规并且有意义的。但是系统部分功能还未实现或者某一个步骤还没开发好，于是，想在表里面手动制造大量的数据是不可能的，只能够使用工具来。于是，在网上搜了一些资料，发现不是使用程序来生成就是一些不怎么好用的工具。于是就想到了平时用得最多的，用来做表结构设计的powerdesigner。下面就powerdesigner反向工程，制造测试数据的过程以及过程中遇到的一些问题说明一下，以便后续需要时查阅。环境：windows10(7,8) powerdesigner15.1 一、 配置odbc数据源配置odbc也非常简单，一张图就够了。 mysql的odbc连接数据源；如果没有MySQL的连接选项，是因为还没有安装mysql的odbc连接驱动。此时可以去官网下载连接驱动，安装完，重新打开就有了。https://dev.mysql.com/downloads/connector/odbc/ 如果要操作的是oracle，没有oracle选项，那么可以从oracle官网下载客户端安装就好了。下载地址：http://www.oracle.com/technetwork/topics/winx64soft-089540.html根据需要下载对于的版本。这里oracle的安装有一些需要注意的地方，可以参考：http://www.cnblogs.com/shelvenn/p/3799849.html安装完成，再点击添加就有了orcale odbc的选项了进行连接数据并测试，连接成功就可以了至此，odbc的配置以及完成。接下来就是powerdegsigner的反向工程了二、powerdesigner的反向工程选择： 文件/File&gt; Reverse Engineer&gt; Database,选择对于的数据库类型和版本连接数据库 此时test Connection出现错误，而在添加odbc的时候正确，是因为powerdesigner使用的是32位的执行jvm，而本地是使用64位的。所以连接不成功。此时，可以修改powerdesigner的jdk配置。工具–&gt;常规选项，配置如下图 注：确保配置的jdk版本是32位。如果发现没有工具菜单下面没有常规选项，是因为powerdesigner还没有破解，可以先破解，方法可以去百度一下，这里就不在累赘如果还是不行，换用32位的odbc，我的是试了所有上述方法之后不行，后来试了这个方法才可以的。是自己刚在安装了64位的odbc数据源了。 至此，反向工程第一步，也就是已经存在数据库表，反向生成PDM模型的过程已经完成。 接下来就是生成模拟数据了。 三、测试数据的生成生成数据: 数据库&gt;Generate test data测试数据的生成也很简单，这里只是列出了针对在定义字段的测试profiles时出现的一些问题的解决方案在定义日期时间的范围的时候，发现年份的定义只有三位数，这个是不合理的，也算是powerdesigner的一个bug吧，但是也不是没有解决方案，看一下这下面这两个图，基本就是可以了。解决方案]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>powerdesigner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql启动和中文字符乱码]]></title>
    <url>%2F2017%2F05%2F05%2Fmysql-charset-error-20170505%2F</url>
    <content type="text"><![CDATA[mysql是使用非常广泛的关系型数据库，在使用过程中经常会遇到一些问题。本篇记录在mysql启动的过程中遇到的问题，以及mysql数据库中文乱码问题的处理。 一、启动报错12345678910111213[root@izwz96tljwj636zfkf3wvqz share]# mysqlERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)[root@izwz96tljwj636zfkf3wvqz share]# mysqld2017-05-04T12:11:42.751767Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).2017-05-04T12:11:42.753370Z 0 [Note] mysqld (mysqld 5.7.18) starting as process 2797 ...2017-05-04T12:11:42.755044Z 0 [ERROR] Fatal error: Please read "Security" section of the manual to find out how to run mysqld as root!2017-05-04T12:11:42.755075Z 0 [ERROR] Aborting2017-05-04T12:11:42.755088Z 0 [Note] Binlog end2017-05-04T12:11:42.755220Z 0 [Note] mysqld: Shutdown complete[root@izwz96tljwj636zfkf3wvqz share]# 为了不让警告mysqld –default-file=/etc/my.cnf –user=root出现，启动mysql时，设置–explicit_defaults_for_timestamp=true即在/etc/my.cnf在[mysqld]下面添加 1explicit_defaults_for_timestamp=true 解决Security的问题在/etc/my.cnf的[mysqld]下面添加 1user=root 使得启动mysql服务时，强行使用root用户启动 二、又一次启动报错了123[root@izwz96tljwj636zfkf3wvqz ~]# service mysqld startStarting mysqld (via systemctl): Job for mysqld.service failed because the control process exited with error code. See "systemctl status mysqld.service" and "journalctl -xe" for details. [FAILED] 处理过程如下 执行&gt;journalctl -ex #查看错误代码 查看mysql日志文件&gt;vim /var/log/mysql.log 进入日志文件，查看后面的错误代码 发现有错误122017-05-04T17:56:59.784551Z 0 [ERROR] unknown variable 'default-character-set=utf8'2017-05-04T17:56:59.784564Z 0 [ERROR] Aborting 解决办法 去掉/etc/my.cnf配置文件的default-character-set属性 三、处理中文字符乱码1234567891011121314mysql&gt; show variables like 'character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec) 此时发现character_set_database和 character_set_server都是latin1的编码 123456789mysql&gt; show create database bangkok;+----------+-----------------------------------------------------------------------------------+| Database | Create Database |+----------+-----------------------------------------------------------------------------------+| bangkok | CREATE DATABASE `bangkok` /*!40100 DEFAULT CHARACTER SET utf8 COLLATE utf8_bin */ |+----------+-----------------------------------------------------------------------------------+1 row in set (0.00 sec)mysql&gt; set character_set_database = utf8;mysql&gt; set character_set_server = utf8; 此时，再执行show variables like ‘char%’;显示的都是utf8；但是重启mysql之后，还是原来未修改的状态。也就是说，刚刚修改的只是当前的session；并没有真正地修改。此时需要配置my.cnf配置文件1234[mysqld]default-storage-engine=INNODBcharacter-set-server=utf8collation-server=utf8_general_ci 重启mysql即可。再使用程序插入数据，终于正常了。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql安装]]></title>
    <url>%2F2017%2F04%2F27%2Finstall-mysql%2F</url>
    <content type="text"><![CDATA[在linux上面安装和在windows上的安装过程还是有一点区别的，这边文章记录了我个人在linux平台上面安装mysql过程中遇到的一些问题和解决方案。 1. 下载安装包，mysql57-community-release-el6-9.noarch.rpm如果下载的安装包放在了window上，需要将安装包上传至linux服务器，可以使用xftp工具从windows put 文件到linux。当然，最简单的还是在linux命令行上面直接&gt; wget mysql57-community-release-el6-9.noarch.rpm； 2. 开始安装 (参考官网)安装仓库 sudo yum localinstall platform-and-version-specific-package-name.rpm 查看 yum list | grep mysql 安装mysql yum -y install mysql-community-server 这个时候可能出现截图中的错误，是因为包的兼容性问题，可以先删除mysql依赖删除依赖 yum remove mysql-libs 安装完成 如果想安装旧版本，如5.5版本，则可以通过yum list mariadb或者yum list mysql 查看有哪些版本可供安装可以直接执行命令yum install mysql或者yum -y install mariadb mariadb-server此时安装的是mysql的一个分支mariadb。mariadb是mysql的一个分支，mysql先后被sun和oracle收购，以防oracle会对mysql做一些认证。 3. 启动mysql服务 service mysql start 4. mysql安装启动完成后，自动生成的root密码 vim /var/log/mysqld.log 或者执行 sudo grep ‘temporary password’ /var/log/mysqld.log 5. 重置密码5.1 先使用初始密码登录1234567 网上可能是建议你这样修改的&gt;mysql -uroot -p 密码&gt;mysql&gt;use mysql;&gt;update user set password=passworD("123456") where user='root';执行update时，报错：ERROR 1046 (3D000): No database selected 5.2 使用官网做法 ALTER USER ‘root‘@’localhost’ IDENTIFIED BY ‘Gz@2017(Kj)’;​&gt;flush privileges; 5.3 直接在shell中执行mysql_secure_installation12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061[root@vultr usr]# mysql_secure_installationNOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY!In order to log into MariaDB to secure it, we'll need the currentpassword for the root user. If you've just installed MariaDB, andyou haven't set the root password yet, the password will be blank,so you should just press enter here.Enter current password for root (enter for none):ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)Enter current password for root (enter for none):OK, successfully used password, moving on...Setting the root password ensures that nobody can log into the MariaDBroot user without the proper authorisation.Set root password? [Y/n] yNew password:Re-enter new password:Password updated successfully!Reloading privilege tables.. ... Success!By default, a MariaDB installation has an anonymous user, allowing anyoneto log into MariaDB without having to have a user account created forthem. This is intended only for testing, and to make the installationgo a bit smoother. You should remove them before moving into aproduction environment.Remove anonymous users? [Y/n] Y ... Success!Normally, root should only be allowed to connect from 'localhost'. Thisensures that someone cannot guess at the root password from the network.Disallow root login remotely? [Y/n] n ... skipping.By default, MariaDB comes with a database named 'test' that anyone canaccess. This is also intended only for testing, and should be removedbefore moving into a production environment.Remove test database and access to it? [Y/n] n ... skipping.Reloading the privilege tables will ensure that all changes made so farwill take effect immediately.Reload privilege tables now? [Y/n] Y ... Success!Cleaning up...All done! If you've completed all of the above steps, your MariaDBinstallation should now be secure.Thanks for using MariaDB![root@vultr usr]# 6. 使用可视化工具连接发现此时还是不能够登录在window上面telnet ip port一下 发现无法telnet到端口因此可以判断是端口没有开放出来。 7. 开放端口号查看端口状态 service status iptables; 如果是centos7版本，则需要使用systemctl，已经不再支持service命令了。此时命令行会有提示。如果还没有安装防火墙，可以先安装 yum install iptables-services 安装完成后，在查看 systemctl status iptables.service 说明已经关闭防火墙了 8. 客户端连接此时如果使用navicat等客户端连接还报错，那么授权一下就可以了。12345mysql&gt; grant all privileges on *.* to root@"%" identified by "yourpassword";Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 其实执行grant all privileges on . to root@”%” identified by “yourpassword”; 就相当与执行insert into mysql.user(Host,User,Password) values(“%”,”root”,password(“yourpassword”)); 也就是往mysql.user插入一条数据。可以通过 select Host ,User , Password from user; 查看效果。 9. 总结总之，安装的过程最好还是按着官网的来。安装过程也因各个linux版本不同而不同。 10. 补充部分上述步骤都完成之后，我在windows用navicat远程连接root，创建一个用户user1，然后给他授权一个刚创建的数据库db1.但是提交的时候失败了。接着，又使用user1试着去连接，还是报错，连接不上；登录服务器使用mysql -uuser1 -p user1password又可以正常连接。于是查了资料，发现在授权的时候需要加一个with grant option；也就是 grant all privileges on db1. to user1@’%’ identified by ‘user1password’ with grant option*; with grant option 的 作用可以参考官网文档；这里简单理解为使用了这个参数之后，就可以就行远程连接了。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[薪资扣税算法]]></title>
    <url>%2F2017%2F04%2F24%2Fsalary%2F</url>
    <content type="text"><![CDATA[1. 计算方法应纳税所得额 = 工资收入金额 － 各项社会保险费 － 起征点(3500元)应纳税额 = 应纳税所得额 x 税率 － 速算扣除数 2. 例子如基本工资4000，加上补贴1200,则公司需要给你发5200元，假设各项社会保险扣除500 1234则扣税计算方法：应缴纳所得税 = 5200 - 500 - 3500 = 12001200在2级数应纳税额 = 1200 * 10% - 105 = 15 元]]></content>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http请求状态码]]></title>
    <url>%2F2017%2F04%2F24%2Fhttp-status-code%2F</url>
    <content type="text"><![CDATA[当用户试图通过 HTTP 访问一台正在运行 Internet 信息服务 (IIS) 的服务器上的内容时，IIS 返回一个表示该请求的状态的数字代码。状态代码可以指明具体请求是否已成功，还可以揭示请求失败的确切原因。 1. 1xx - 信息提示这些状态代码表示临时的响应。客户端在收到常规响应之前，应准备接收一个或多个 1xx 响应。 100 - Continue 初始的请求已经接受，客户应当继续发送请求的其余部分。（HTTP 1.1新） 101 - Switching Protocols 服务器将遵从客户的请求转换到另外一种协议（HTTP 1.1新） 2. 2xx - 成功这类状态代码表明服务器成功地接受了客户端请求。 200 - OK 一切正常，对GET和POST请求的应答文档跟在后面。 201 - Created 服务器已经创建了文档，Location头给出了它的URL。 202 - Accepted 已经接受请求，但处理尚未完成。 203 - Non-Authoritative Information 文档已经正常地返回，但一些应答头可能不正确，因为使用的是文档的拷贝，非权威性信息（HTTP 1.1新）。 204 - No Content 没有新文档，浏览器应该继续显示原来的文档。如果用户定期地刷新页面，而Servlet可以确定用户文档足够新，这个状态代码是很有用的。 205 - Reset Content 没有新的内容，但浏览器应该重置它所显示的内容。用来强制浏览器清除表单输入内容（HTTP 1.1新）。 206 - Partial Content 客户发送了一个带有Range头的GET请求，服务器完成了它（HTTP 1.1新）。 3. 3xx - 重定向客户端浏览器必须采取更多操作来实现请求。例如，浏览器可能不得不请求服务器上的不同的页面，或通过代理服务器重复该请求。 300 - Multiple Choices 客户请求的文档可以在多个位置找到，这些位置已经在返回的文档内列出。如果服务器要提出优先选择，则应该在Location应答头指明。 301 - Moved Permanently 客户请求的文档在其他地方，新的URL在Location头中给出，浏览器应该自动地访问新的URL。 302 - Found 类似于301，但新的URL应该被视为临时性的替代，而不是永久性的。注意，在HTTP1.0中对应的状态信息是“Moved Temporatily”。出现该状态代码时，浏览器能够自动访问新的URL，因此它是一个很有用的状态代码。注意这个状态代码有时候可以和301替换使用。例如，如果浏览器错误地请求 http://host/~user （缺少了后面的斜杠），有的服务器返回301，有的则返回302。严格地说，我们只能假定只有当原来的请求是GET时浏览器才会自动重定向。请参见 307。 303 - See Other 类似于301/302，不同之处在于，如果原来的请求是POST，Location头指定的重定向目标文档应该通过GET提取（HTTP 1.1新）。 304 - Not Modified 客户端有缓冲的文档并发出了一个条件性的请求（一般是提供If-Modified-Since头表示客户只想比指定日期更新的文档）。服务器告诉客户，原来缓冲的文档还可以继续使用。 305 - Use Proxy 客户请求的文档应该通过Location头所指明的代理服务器提取（HTTP 1.1新）。 307 - Temporary Redirect 和302（Found）相同。许多浏览器会错误地响应302应答进行重定向，即使原来的请求是POST，即使它实际上只能在POST请求的应答是303时才能重定向。由于这个原因，HTTP 1.1新增了307，以便更加清除地区分几个状态代码：当出现303应答时，浏览器可以跟随重定向的GET和POST请求；如果是307应答，则浏览器只能跟随对GET请求的重定向。（HTTP 1.1新） 4. 4xx - 客户端错误发生错误，客户端似乎有问题。例如，客户端请求不存在的页面，客户端未提供有效的身份验证信息。 400 - Bad Request 请求出现语法错误。 401 - Unauthorized 访问被拒绝，客户试图未经授权访问受密码保护的页面。应答中会包含一个WWW-Authenticate头，浏览器据此显示用户名字/密码对话框，然后在填写合适的Authorization头后再次发出请求。IIS 定义了许多不同的 401 错误，它们指明更为具体的错误原因。这些具体的错误代码在浏览器中显示，但不在 IIS 日志中显示： 401.1 - 登录失败。 401.2 - 服务器配置导致登录失败。 401.3 - 由于 ACL 对资源的限制而未获得授权。 401.4 - 筛选器授权失败。 401.5 - ISAPI/CGI 应用程序授权失败。 401.7 – 访问被 Web 服务器上的 URL 授权策略拒绝。这个错误代码为 IIS 6.0 所专用。 403 - Forbidden 资源不可用。服务器理解客户的请求，但拒绝处理它。通常由于服务器上文件或目录的权限设置导致。禁止访问：IIS 定义了许多不同的 403 错误，它们指明更为具体的错误原因： 403.1 - 执行访问被禁止。 403.2 - 读访问被禁止。 403.3 - 写访问被禁止。 403.4 - 要求 SSL。 403.5 - 要求 SSL 128。 403.6 - IP 地址被拒绝。 403.7 - 要求客户端证书。 403.8 - 站点访问被拒绝。 403.9 - 用户数过多。 403.10 - 配置无效。 403.11 - 密码更改。 403.12 - 拒绝访问映射表。 403.13 - 客户端证书被吊销。 403.14 - 拒绝目录列表。 403.15 - 超出客户端访问许可。 403.16 - 客户端证书不受信任或无效。 403.17 - 客户端证书已过期或尚未生效。 403.18 - 在当前的应用程序池中不能执行所请求的 URL。这个错误代码为 IIS 6.0 所专用。 403.19 - 不能为这个应用程序池中的客户端执行 CGI。这个错误代码为 IIS 6.0 所专用。 403.20 - Passport 登录失败。这个错误代码为 IIS 6.0 所专用。 404 - Not Found 无法找到指定位置的资源。这也是一个常用的应答。 404.0 -（无） – 没有找到文件或目录。 404.1 - 无法在所请求的端口上访问 Web 站点。 404.2 - Web 服务扩展锁定策略阻止本请求。 404.3 - MIME 映射策略阻止本请求。 405 - Method Not Allowed 请求方法（GET、POST、HEAD、Delete、PUT、TRACE等）对指定的资源不适用，用来访问本页面的 HTTP 谓词不被允许（方法不被允许）（HTTP 1.1新） 406 - Not Acceptable 指定的资源已经找到，但它的MIME类型和客户在Accpet头中所指定的不兼容，客户端浏览器不接受所请求页面的 MIME 类型（HTTP 1.1新）。 407 - Proxy Authentication Required 要求进行代理身份验证，类似于401，表示客户必须先经过代理服务器的授权。（HTTP 1.1新） 408 - Request Timeout 在服务器许可的等待时间内，客户一直没有发出任何请求。客户可以在以后重复同一请求。（HTTP 1.1新） 409 - Conflict 通常和PUT请求有关。由于请求和资源的当前状态相冲突，因此请求不能成功。（HTTP 1.1新） 410 - Gone 所请求的文档已经不再可用，而且服务器不知道应该重定向到哪一个地址。它和404的不同在于，返回407表示文档永久地离开了指定的位置，而404表示由于未知的原因文档不可用。（HTTP 1.1新） 411 - Length Required 服务器不能处理请求，除非客户发送一个Content-Length头。（HTTP 1.1新） 412 - Precondition Failed 请求头中指定的一些前提条件失败（HTTP 1.1新）。 413 – Request Entity Too Large 目标文档的大小超过服务器当前愿意处理的大小。如果服务器认为自己能够稍后再处理该请求，则应该提供一个Retry-After头（HTTP 1.1新）。 414 - Request URI Too Long URI太长（HTTP 1.1新）。 415 – 不支持的媒体类型。 416 – Requested Range Not Satisfiable 服务器不能满足客户在请求中指定的Range头。（HTTP 1.1新） 417 – 执行失败。 423 – 锁定的错误。 5. 5xx - 服务器错误服务器由于遇到错误而不能完成该请求。 500 - Internal Server Error 服务器遇到了意料不到的情况，不能完成客户的请求。 500.12 - 应用程序正忙于在 Web 服务器上重新启动。 500.13 - Web 服务器太忙。 500.15 - 不允许直接请求 Global.asa。 500.16 – UNC 授权凭据不正确。这个错误代码为 IIS 6.0 所专用。 500.18 – URL 授权存储不能打开。这个错误代码为 IIS 6.0 所专用。 500.100 - 内部 ASP 错误。 501 - Not Implemented 服务器不支持实现请求所需要的功能，页眉值指定了未实现的配置。例如，客户发出了一个服务器不支持的PUT请求。 502 - Bad Gateway 服务器作为网关或者代理时，为了完成请求访问下一个服务器，但该服务器返回了非法的应答。 亦说Web 服务器用作网关或代理服务器时收到了无效响应。 502.1 - CGI 应用程序超时。 502.2 - CGI 应用程序出错。 503 - Service Unavailable 服务不可用，服务器由于维护或者负载过重未能应答。例如，Servlet可能在数据库连接池已满的情况下返回503。服务器返回503时可以提供一个 Retry-After头。这个错误代码为 IIS 6.0 所专用。 504 - Gateway Timeout 网关超时，由作为代理或网关的服务器使用，表示不能及时地从远程服务器获得应答。（HTTP 1.1新） 。 505 - HTTP Version Not Supported 服务器不支持请求中所指明的HTTP版本。（HTTP 1.1新）。]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ip地址分类]]></title>
    <url>%2F2017%2F04%2F24%2Fip-address%2F</url>
    <content type="text"><![CDATA[IP地址分类可以分为三类：A类、B类和C类。 1. A类IP地址一个A类IP地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”， 地址范围从1.0.0.0 到126.0.0.0。可用的A类网络有126个，每个网络能容纳1亿多个主机。 需要注意的是网络号不能为127，这是因为该网络号被保留用作回路及诊断功能。 2. B类IP地址一个B类IP地址由2个字节的网络地址和2个字节的主机地址组成，网络地址的最高位必须是“10”，地址范围从128.0.0.0到191.255.255.255。可用的B类网络有16382个，每个网络能容纳6万多个主机。 3. C类IP地址一个C类IP地址由3字节的网络地址和1字节的主机地址组成，网络地址的最高位必须是“110”。范围从192.0.0.0到223.255.255.255。C类网络可达209万余个，每个网络能容纳254个主机。 什么叫网络地址的最高位B类地址是用32 位地址中的最高位模式来识别的，如：10XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX（32位），最高位的“10”代表它是B类的。B 类地址的前16 位代表网络号，剩余的16位可由管理网络地址的用户来修改。 4. 局域网ip段私有IP地址范围： A类：10.0.0.0-10.255.255.255 B类：172.16.0.0-172.31.255.255 C类：192.168.0.0-192.168.255.255]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[get and post]]></title>
    <url>%2F2017%2F04%2F18%2Fget-and-post%2F</url>
    <content type="text"><![CDATA[GET POST 区别详解 Get是用来从服务器上获得数据，而Post是用来向服务器上传递数据。 Get将表单中数据的按照variable=value的形式，添加到action所指向的URL后面，并且两者使用“?”连接，而各个变量之间使用“&amp;”连接；Post是将表单中的数据放在form的数据体中，按照变量和值相对应的方式，传递到action所指向URL。 Get是不安全的，因为在传输过程，数据被放在请求的URL中，而如今现有的很多服务器、代理服务器或者用户代理都会将请求URL记录到日志文件中，然后放在某个地方，这样就可能会有一些隐私的信息被第三方看到。另外，用户也可以在浏览器上直接看到提交的数据，一些系统内部消息将会一同显示在用户面前。Post的所有操作对用户来说都是不可见的。 Get传输的数据量小，这主要是因为受URL长度限制,大约是4K；而Post可以传输大量的数据，所以在上传文件只能使用Post（当然还有一个原因，将在后面的提到）。 Get限制Form表单的数据集的值必须为ASCII字符；而Post支持整个ISO10646字符集。默认是用ISO-8859-1编码 Get是Form的默认方法。 Java web开发中表单提交的方式 get方式 首先说下客户端（浏览器）的form表单用get方法是如何将数据编码后提交给服务器端的吧？ 对于get方法来说，都是把数据串联在请求的url后面作为参数，如：http://localhost:8080/servlet?msg=abc（很常见的一个乱码问题就要出现了，如果url中出现中文或其它特殊字符的话，如：http://localhost:8080 /servlet?msg=杭州，服务器端容易得到乱码），url拼接完成后，浏览器会对url进行URL encode，然后发送给服务器，URL encode的过程就是把部分url做为字符，按照某种编码方式（如：utf-8,gbk等）编码成二进制的字节码，然后每个字节用一个包含3个字符的字符串 “%xy” 表示，其中xy为该字节的两位十六进制表示形式。我这里说的可能不清楚，具体介绍可以看下java.net.URLEncoder类的介绍在这里。了解了 URL encode的过程，我们能看到2个很重要的问题，第一：需要URL encode的字符一般都是非ASCII的字符（笼统的讲），再通俗的讲就是除了英文字母以外的文字（如：中文，日文等）都要进行URL encode，所以对于我们来说，都是英文字母的url不会出现服务器得到乱码问题，出现乱码都是url里面带了中文或特殊字符造成的；第二：URL encode到底按照那种编码方式对字符编码？这里就是浏览器的事情了，而且不同的浏览器有不同的做法，中文版的浏览器一般会默认的使用GBK，通过设置浏览器也可以使用UTF-8，可能不同的用户就有不同的浏览器设置，也就造成不同的编码方式，所以很多网站的做法都是先把url里面的中文或特殊字符用 javascript做URL encode，然后再拼接url提交数据，也就是替浏览器做了URL encode，好处就是网站可以统一get方法提交数据的编码方式。 完成了URL encode，那么现在的url就成了ASCII范围内的字符了，然后以iso-8859-1的编码方式转换成二进制随着请求头一起发送出去。这里想多说几句的是，对于get方法来说，没有请求实体，含有数据的url都在请求头里面，之所以用URL encode，我个人觉的原因是：对于请求头来说最终都是要用iso-8859-1编码方式编码成二进制的101010…..的纯数据在互联网上传送，如果直接将含有中文等特殊字符做iso-8859-1编码会丢失信息，所以先做URL encode是有必要的。 服务器端（tomcat）是如何将数据获取到进行解码的第一步是先把数据用iso-8859-1进行解码，对于get方法来说，tomcat获取数据的是ASCII范围内的请求头字符，其中的请求url里面带有参数数据，如果参数中有中文等特殊字符，那么目前还是URL encode后的%XY状态，先停下，我们先说下开发人员一般获取数据的过程。通常大家都是request.getParameter(“name”)获取参数数据，我们在request对象或得的数据都是经过解码过的，而解码过程中程序里是无法指定，这里要说下，有很多新手说用 request.setCharacterEncoding(“字符集”)可以指定解码方式，其实是不可以的，看servlet的官方API说明有对此方法的解释：Overrides the name of the character encoding used in the body of this request. This method must be called prior to reading request parameters or reading input using getReader().可以看出对于get方法他是无能为力的。那么到底用什么编码方式解码数据的呢，这是tomcat的事情了，默认缺省用的是 iso-8859-1,这样我们就能找到为什么get请求带中文参数为什么在服务器端得到乱码了，原因是在客户端一般都是用UTF-8或GBK对数据 URL encode，这里用iso-8859-1方式URL decoder显然不行。 解决办法 new String(request.getParameter(“name”).getBytes(“iso-8859-1”),”客户端指定的URL encode编码方式”),还原回字节码，然后用正确的方式解码数据，网上的文章通常是在tomcat里面做个配置Xml代码 这样是让tomcat在获取数据后用指定的方式URL decoder，URL decoder的介绍在这里.1&lt;Connector port="8080" protocol="HTTP/1.1" maxThreads="150" connectionTimeout="20000" redirectPort="8443" URIEncoding="GBK"/&gt; post方式 客户端（浏览器）的form表单用post方法是如何将数据编码后提交给服务器端的。在post方法里所要传送的数据也要URL encode，那么他是用什么编码方式的呢？在form所在的html文件里如果有段，那么post就会用此处指定的编码方式编码。一般大家都认为这段代码是为了让浏览器知道用什么字符集来对网页解释，所以网站都会把它放在html代码的最前端，尽量不出现乱码，其实它还有个作用就是指定form表单的post方法提交数据的 URL encode编码方式。从这里可以看出对于get方法来数，浏览器对数据的URL encode的编码方式是有浏览器设置来决定，（可以用js做统一指定），而post方法，开发人员可以指定。 服务器端（tomcat）是如何将数据获取到进行解码的。如果用tomcat默认缺省设置，也没做过滤器等编码设置，那么他也是用iso-8859-1解码的，但是request.setCharacterEncoding(“字符集”)可以派上用场。 我发现上面说的tomcat所做的事情前提都是在请求头里没有指定编码方式，如果请求头里指定了编码方式将按照这种方式编码。 有2篇文章推荐下，地址分别是深入浅出URL编码：http://www.cnblogs.com/yencain/articles/1321386.html；表单用post方法提交数据时乱码问题：http://wanghuan8086.javaeye.com/blog/173869 用post很重要的在form所在的html文件里如果有段强烈建议使用post提交 总结get请求过程：如果表单中包含中文，浏览器会URL encode （通常为UTF-8,GBK），编码之后的参数变成ASCII码范围的数据，然后再用ISO-8859-1转换成二进制流，和请求头一起在网络上传输。 服务器如何操作：1.使用给定的 charset 将此 String 编码到 byte 序列 .通过使用指定的 charset 解码指定的 byte 数组，构造一个新的 Stringbyte [] dest=request.getParameter(“name”).getBytes(“iso-8859-1”);String str=new String(dest,”utf-8”);2：String str1=URLEncoder.encode(name,”iso-8859-1”);String str2=URLDecoder.decode(str1,”utf-8”);s]]></content>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[servlet的监听器、过滤器和拦截器]]></title>
    <url>%2F2017%2F04%2F18%2Fservlet%2F</url>
    <content type="text"><![CDATA[servlet的监听器、过滤器和拦截器filter和listener 一、监听器servlet2.4中定义了三个接口：ServletContextListener,HttpSessionListener,ServletRequestListener。分别实现对应的接口就可以实现对应的监听处理 二、监听器类型按监听的对象划分：servlet2.4规范定义的事件有三种： 用于监听应用程序环境对象（ServletContext）的事件监听器 用于监听用户会话对象（HttpSession）的事件监听器 用于监听请求消息对象（ServletRequest）的事件监听器 按监听的事件类项划分 用于监听域对象自身的创建和销毁的事件监听器 用于监听域对象中的属性的增加和删除的事件监听器 用于监听绑定到HttpSession域中的某个对象的状态的事件监听器 在一个web应用程序的整个运行周期内，web容器会创建和销毁三个重要的对象，ServletContext，HttpSession,ServletRequest。 三、分类及介绍 ServletContextListener：用于监听WEB 应用启动和销毁的事件，监听器类需要实现javax.servlet.ServletContextListener 接口。 ServletContextAttributeListener：用于监听WEB应用属性改变的事件，包括：增加属性、删除属性、修改属性，监听器类需要实现javax.servlet.ServletContextAttributeListener接口。 HttpSessionListener： 用于监听Session对象的创建和销毁，监听器类需要实现javax.servlet.http.HttpSessionListener接口或者 javax.servlet.http.HttpSessionActivationListener接口，或者两个都实现。 HttpSessionActivationListener： 用于监听Session对象的钝化/活化事件，监听器类需要实现javax.servlet.http.HttpSessionListener接口或者 javax.servlet.http.HttpSessionActivationListener接口，或者两个都实现。 HttpSessionAttributeListener：用于监听Session对象属性的改变事件，监听器类需要实现javax.servlet.http.HttpSessionAttributeListener接口。 四、拦截器与过滤器的区别 拦截器是基于java的反射机制的，而过滤器是基于函数回调。 拦截器不依赖与servlet容器，过滤器依赖与servlet容器。 拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。 拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。 在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次 执行顺序：过滤前 – 拦截前 – Action处理 – 拦截后 – 过滤后。个人认为过滤是一个横向的过程，首先把客户端提交的内容进行过滤(例如未登录用户不能访问内部页面的处理)；过滤通过后，拦截器将检查用户提交数据的验证，做一些前期的数据处理，接着把处理后的数据发给对应的Action；Action处理完成返回后，拦截器还可以做其他过程(还没想到要做啥)，再向上返回到过滤器的后续操作。]]></content>
      <tags>
        <tag>servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk tools（jdk自带小工具）]]></title>
    <url>%2F2017%2F04%2F18%2Fjdk-tools%2F</url>
    <content type="text"><![CDATA[jre/bin目录下面工具说明javac ：Java编译器，将Java源代码换成字节代java ：Java解释器，直接从类文件执行Java应用程序代码appletviewer(小程序浏览器)：一种执行HTML文件上的Java小程序类的Java浏览器javadoc：根据Java源代码及其说明语句生成的HTML文档jdb：Java调试器，可以逐行地执行程序、设置断点和检查变量javah：产生可以调用Java过程的C过程，或建立能被Java程序调用的C过程的头文件Javap：Java反汇编器，显示编译类文件中的可访问功能和数据，同时显示字节代码含义jar：多用途的存档及压缩工具，是个java应用程序，可将多个文件合并为单个JAR归档文件。htmlConverter——命令转换工具。native2ascii——将含有不是Unicode或Latinl字符的的文件转换为Unicode编码字符的文件。serialver——返回serialverUID。语法：serialver [show] 命令选项show是用来显示一个简单的界面。输入完整的类名按Enter键或”显示”按钮，可显示serialverUID。 jdk\bin目录下工具说明appletviewer.exe(小程序浏览器)：一种执行HTML文件上的Java小程序类的Java浏览器apt.exe：SolarisTM 操作系统和 Linux上用于处理注释的工具extcheck.exe：检测目标 jar 文件与当前安装方式扩展 jar 文件间的版本冲突。HtmlConverter.exe:Java(TM) 插件 HTML 转换器是一种实用程序，可用于将任一包含小程序的 HTML 页面,转换为使用 Java(TM)插件的格式。idlj.exe：对idl文件进行解析，生成所需的java文件jar：多用途的存档及压缩工具，是个java应用程序，可将多个文件合并为单个JAR归档文件。jarsigner：为 Java 归档 (JAR) 文件产生签名，并校验已签名的 JAR 文件的签名java：Java解释器，直接从类文件执行Java应用程序代码javac：Java编译器，将Java源代码换成字节代javadoc：根据Java源代码及其说明语句生成的HTML文档javah：产生可以调用Java过程的C过程，或建立能被Java程序调用的C过程的头文件Javap：Java反汇编器，显示编译类文件中的可访问功能和数据，同时显示字节代码含义java-rmi:javaw:与java类似，没有控制台信息javaws:用于启动和控制Web上的java是程序JConsole:是一个基于JMX的GUI工具，用于连接正在运行的JVM，不过此JVM需要使用可管理的模式启动。jdb:用于调试java程序的工具jhat：是一个Java堆复制浏览器。这个工具分析Java堆复制文件（例如，由上面的”jmap -dump”所产生的）。Jhat启动一个允许堆中的对象在web浏览器中进行分析的web服务器。这个工具并不是想用于应用系统中而是用于”离线”分 析。”jhat工具是平台独立的”，其意思是，它可以被用来观察在任何平台上所产生的堆复制。例如，我们有可能在Linux系统上使用jhat来观察一个 在Solaris OS上所产生的堆复制。jinfo：打印一个给定的Java进程或核心文件或一个远程调试服务器的Java配置信息。配置信息包括Java系统属性和JVM命令行标志jps：相当于Solaris进程工具ps。不象”pgrep java”或”ps -ef grep java”，jps并不使用应用程序名来查找JVM实例。因此，它查找所有的Java应用程序，包括即使没有使用java执行体的那种（例如，定制的启动 器）。另外，jps仅查找当前用户的Java进程，而不是当前系统中的所有进程。jrunscript：一个JS解释器jstack：等价于Solaris的pstack工具。jstack打印所有的Java线程的堆栈跟踪信息（可选地包括本机帧信息）jstat ：显示一个测量（instrumented）Java HotSpot虚拟机的性能统计信息jstatd是一个Java远程方法调用 (RMI)服务器应用程序-它监控测量Java HotSpot虚拟机的创建和终止并且提供一个接口来允许远程监控工具依附到运行于本地主机的JVMKeytool：是安全钥匙与证书的管理工具，它管理一个存储了私有钥匙和验证相应公共钥匙的与它们相关联的X.509 证书链的keystorekint,klist,ktab:实现Kerberos用到的一些工具native2ascii：用于转换字符或者文件的编码格式orbd：用于实现corba接口（分布式应用）pack200：对jar文件进行高效的压缩packager: 将Jar文件包装成其他格式的文件policytool：java中的策略管理rmic：为远程调用编译生成远程调用时所需的文件rmid：用于启动激活系统守护进程，以便远程对象可以在JVM中注册和激活rmiregistry：启动一个远程对象注册表中指定的端口schemagen:serialver：用于返回一个类的serialverUIDservertools：为程序员提供了一个命令行接口，用于注册，取消注册，启动，关闭一个服务tnameserv：unpack200：对pack200进行压缩的jar文件进行解压wsgen：是一个命令行功能用来生成合适的JAX-WS。它读取WebService的终端类文件，同时生成所有用于WebService发布的源代码文件和经过编译过的二进制类文件。它还随意生成WSDL和符合规范的HelloServer类WebService。wsgen从资源文件生成一个完整的操作列表是合法的。wsimport：这个工具依据wsdl文件生成相应的类文件，然后用这些类文件，就可以像调用本地的类一样调用WebService提供的方法了]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种数据库的jdbc连接]]></title>
    <url>%2F2017%2F04%2F18%2Fjdbc-connection%2F</url>
    <content type="text"><![CDATA[jdbc连接多种数据库的连接方式1. Oracle8/8i/9i数据库（thin模式）123456Class.forName("oracle.jdbc.driver.OracleDriver").newInstance();String url="jdbc:oracle:thin:@localhost:1521:orcl";//orcl为数据库的SIDString user="test";String password="test";Connection conn= DriverManager.getConnection(url,user,password); 2. DB2数据库123456Class.forName("com.ibm.db2.jdbc.app.DB2Driver ").newInstance();String url="jdbc:db2://localhost:5000/sample";//sample为你的数据库名String user="admin";String password="";Connection conn= DriverManager.getConnection(url,user,password); 3. Sql Server7.0/2000数据库123456Class.forName("com.microsoft.jdbc.sqlserver.SQLServerDriver").newInstance();String url="jdbc:microsoft:sqlserver://localhost:1433;DatabaseName=mydb";//mydb为数据库String user="sa";String password="";Connection conn= DriverManager.getConnection(url,user,password); 4. Sybase数据库1234567Class.forName("com.sybase.jdbc.SybDriver").newInstance();String url =" jdbc:sybase:Tds:localhost:5007/myDB";//myDB为你的数据库名Properties sysProps = System.getProperties();SysProps.put("user","userid");SysProps.put("password","user_password");Connection conn= DriverManager.getConnection(url, SysProps); 5. Informix数据库1234Class.forName("com.informix.jdbc.IfxDriver").newInstance();String url ="jdbc:informix-sqli://123.45.67.89:1533/myDB:INFORMIXSERVER=myserver;user=testuser;password=testpassword";//myDB为数据库名Connection conn= DriverManager.getConnection(url); 6. MySQL数据库1234Class.forName("org.gjt.mm.mysql.Driver").newInstance();String url ="jdbc:mysql://localhost/myDB?user=soft&amp;password=soft1234&amp;useUnicode=true&amp;characterEncoding=8859_1"//myDB为数据库名Connection conn= DriverManager.getConnection(url); 7. PostgreSQL数据库123456Class.forName("org.postgresql.Driver").newInstance();String url ="jdbc:postgresql://localhost/myDB"//myDB为数据库名String user="myuser";String password="mypassword";Connection conn= DriverManager.getConnection(url,user,password);]]></content>
      <categories>
        <category>jdbc</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用设计模式]]></title>
    <url>%2F2017%2F04%2F18%2FDesign-Pattern%2F</url>
    <content type="text"><![CDATA[什么是设计模式 个人理解就是一种编码习惯，前人总结下来的代码编写习惯。每一个模式针对某一类问题的一种优雅的处理办法。 一、 设计模式概述 为什么要学习设计模式 1. 是开发人员或这几人员交流的通用语言; 2. 更好的使得代码更加优雅，灵活，易懂; 3. 代码复用性更高; 4. 是否了解设计模式作为一个程序员的水平标准. 设计模式分类 1. 创建型模式：单例模式，工厂方法，抽象工厂，生成器，原型 2. 结构型模式：适配器，桥接，组合，装饰，外观，享元，代理 3. 行为型模式：责任链，命令，解释器，迭代器，中介者，备忘录，观察者，状态，策略，模板方法，访问者 二、 常用设计模式 1. 策略模式定义了算法族，分别封装起来，让它们之间可以相互替换，此模式让算法的变化独立于使用算法的客户。 设计原则：封装变化；针对接口编程，不针对实现编程；多用组合，少用继承 2. 观察者模式定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。 设计原则：为了交互对象之间的松耦合设计而努力 3. 装饰者模式动态地将责任附加到对象上，若要扩展功能，装饰者模式提供了比继承更有弹性的替代方案。 设计原则：类应该对扩展开放，对修改关闭 4. 简单工厂其实并不是一个设计模式，反而比较像是一张编程习惯。经常被使用。所有工厂模式都是用来封装对象的创建。工厂方法模式通过让子类决定该创建的对象是什么，来达到将对象创建的过程封装的目的。 5. 工厂方法模式定义一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法模式把实例化推迟到子类。 依赖倒置原则：要依赖抽象，不要依赖具体类 6. 抽象工厂模式提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。 7. 单件模式确保一个类只有一个实例，并提供一个全局访问点。 8. 命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也支持对撤销的操作。 9. 适配器模式将一个类的接口，转换成客户期望的另一个接口。适配器让原来不兼容的的类可以合作无间。针对问题：接口不适配，举例说明。 设计原则：使用对象组合，以修改的接口包装被适配者。 10. 外观模式提供一个统一的接口，用来访问子系统中的一群接口。外观定义一个高层接口，让子系统更容易使用。 最少知识原则：只和你的密友谈话 11. 模板方法模式在一个算法中定义一个算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。 好莱坞原则：别调用（打电话给）我们，我们会调用（打电话给）你 12. 迭代器模式提供一种方法顺序访问一个聚合对象中的某个元素，而又不暴露其内部的表示。 设计原则：一个类应该只有一个引起变化的原因 13. 组合模式允许你将对象组合成树形结构来表现“整体/部分”层次结构。组合能让客户以一致的方式处理个别对象以及对象组合。 14. 状态模式允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类。 15. 代理模式为另一个对象提供一个替身后占位符以控制对这个对象的访问。 16. 复合模式复合模式结合两个或以上的模式，组成一个解决方案，解决一再发生的一般性问题。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[注册系统服务(windows)]]></title>
    <url>%2F2017%2F04%2F18%2F%E6%B3%A8%E5%86%8C%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1-windows%2F</url>
    <content type="text"><![CDATA[一、Tomcat变成自动启动的服务 在环境变量中设置JAVA_HOME(假设JDK目录为d:\jdk1.4.2_04) A、进入windows桌面，右键选择“我的电脑”–&gt;“属性” B、选择“高级”页签，点开“环境变量” C、在“系统变量”下点击新建弹出“新建系统变量”，变量名输入“JAVA_HOME”，变量值输入“d:\jdk1.4.2_04”后点击确定 将Tomcat设置成服务(假设Tomcat目录为d:\Tomcat_oa) A、点击开始–&gt;运行，输入cmd进入dos控制台 B、执行以下dos命令(输入命令后按回车键执行)d: cd Tomcat_oa\bin service install 服务名(可选，默认为tomcat5) 此时Tomcat服务已经成功安装。 进入系统服务将服务启动，并将服务设置成自动启动 服务移除 基本操作同2，最后执行service remove 服务名特殊问题处理 如果服务启动失败，检查windows的system目录下(如：c:\windows\system)是否有msvcr71.dll 如果没有的话将jdk\bin目录下的msvcr71.dll拷贝至windows的system. 二、mysql注册成系统服务 进入mysql的安装目录下的bin目录，执行：mysqld –install 服务名(可选) 如果出现“install/remove of the service denied”错误，则重新用管理员身份进入cmd删除服务：sc delete 服务名]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>service</tag>
      </tags>
  </entry>
</search>
